{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyze how important the start weights are for a CNN.\n",
    "\n",
    "**Key question: Do the start weights have a small or large influence on the final classification performance of a CNN?**\n",
    "\n",
    "For this we conduct experiments where we start with different start weights and train a CNN till a certain classification performance is reached and then observe:\n",
    "\n",
    "- Do the training curves differ regarding their form?\n",
    "- How long does it take to reach the final classification performance threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets used for the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image datasets needed in order to conduct the experiments:\n",
    "- imagenette2: 10 very different object classes\n",
    "- imagewoof  : 10 similar object classes (10 dog breeds)\n",
    "\n",
    "Here I use the imagenette2 and imagewoof (both in the 320px versions) datasets which are available at\n",
    "\n",
    "[https://github.com/fastai/imagenette](https://github.com/fastai/imagenette)\n",
    "\n",
    "These are much smaller versions of the original imagenet dataset with only 10 object classes each.\n",
    "\n",
    "You have to download the images manually before starting the experiments!\n",
    "\n",
    "I used the 320px versions of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to image_dataset class v1.0 by Juergen Brauer\n",
      "Under root folder\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train/\n",
      "I have found the following 10 subfolders/classes:\n",
      "\n",
      "['cassette_player', 'chain_saw', 'church', 'dog_english_springer', 'fish_tench', 'french_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute']\n",
      "993 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/\n",
      "858 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//chain_saw/\n",
      "941 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//church/\n",
      "955 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//dog_english_springer/\n",
      "963 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//fish_tench/\n",
      "956 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//french_horn/\n",
      "961 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//garbage_truck/\n",
      "931 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//gas_pump/\n",
      "951 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//golf_ball/\n",
      "960 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//parachute/\n",
      "In total there are 50 images\n",
      "\n",
      "Here are the first 3 entries in the list:\n",
      "Entry #0:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/n02979186_21256.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #1:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/ILSVRC2012_val_00000557.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #2:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/ILSVRC2012_val_00002034.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Under root folder\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val/\n",
      "I have found the following 10 subfolders/classes:\n",
      "\n",
      "['cassette_player', 'chain_saw', 'church', 'dog_english_springer', 'fish_tench', 'french_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute']\n",
      "357 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/\n",
      "386 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//chain_saw/\n",
      "409 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//church/\n",
      "395 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//dog_english_springer/\n",
      "387 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//fish_tench/\n",
      "394 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//french_horn/\n",
      "389 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//garbage_truck/\n",
      "419 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//gas_pump/\n",
      "399 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//golf_ball/\n",
      "390 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//parachute/\n",
      "In total there are 50 images\n",
      "\n",
      "Here are the first 3 entries in the list:\n",
      "Entry #0:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00008651.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #1:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00020400.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #2:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00028911.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "img_shape = (224,224,3)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../cnn_toolbox\")\n",
    "from cnn_toolbox import image_dataset\n",
    "\n",
    "root_folder = \"/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/\"\n",
    "root_folder_train = root_folder + \"train/\"\n",
    "root_folder_test  = root_folder + \"val/\"\n",
    "\n",
    "ds_train = image_dataset(name=\"imagenette2\",\n",
    "                         root_folder=root_folder_train,\n",
    "                         img_size=(img_shape[0],img_shape[1]))\n",
    "\n",
    "ds_test = image_dataset(name=\"imagenette2\",\n",
    "                        root_folder=root_folder_test,\n",
    "                        img_size=(img_shape[0],img_shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to build CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              526336    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 3,504,394\n",
      "Trainable params: 3,504,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import create_cnn_model\n",
    "\n",
    "model1 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 8,407,882\n",
      "Trainable params: 8,407,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = create_cnn_model(model_name = \"inc_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to train a CNN for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import train_cnn_one_epoch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.set_mini_batch_size(128)\n",
    "#train_cnn_one_epoch(model1, ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to test a CNN with a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import test_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_cnn(model1, ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check availability of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following GPUs are available: []\n",
      "Nr of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import gpu_check\n",
    "gpu_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for checking on a computer with NVIDIA GPUs, whether they are used during training, enter:\n",
    "\n",
    "    watch -n1.0 nvidia-smi   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check controlability of start weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import initialize_pseudo_random_number_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_pseudo_random_number_generators(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              526336    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 3,504,394\n",
      "Trainable params: 3,504,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import get_weights_from_conv_layer\n",
    "\n",
    "filter_weights_1, bias_weights_1 = get_weights_from_conv_layer(model1, \"conv2d\", show_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = filter_weights_1[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00225292, -0.02375937, -0.04370089],\n",
       "        [ 0.01732371, -0.04943231,  0.02387507],\n",
       "        [ 0.03352253, -0.01579722,  0.04878741]],\n",
       "\n",
       "       [[-0.0136955 , -0.02521811, -0.04715899],\n",
       "        [ 0.04738381,  0.05001703, -0.03145186],\n",
       "        [ 0.04049386,  0.02348245,  0.01627743]],\n",
       "\n",
       "       [[ 0.02415584,  0.03840971, -0.01027263],\n",
       "        [ 0.03119494, -0.02915212, -0.03134566],\n",
       "        [ 0.02180289,  0.04078788,  0.01119361]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_weights_2, bias_weights_2 = get_weights_from_conv_layer(model2, \"conv2d\", show_info=True)\n",
    "f2 = filter_weights_2[:,:,:,0]\n",
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the random number generators\n",
    "# with the same random seed that we used when\n",
    "# we generated model1a\n",
    "initialize_pseudo_random_number_generators(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "model3 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)\n",
    "filter_weights_3, bias_weights_3 = get_weights_from_conv_layer(model3, \"conv2d\", show_info=True)\n",
    "f3 = filter_weights_3[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00225292, -0.02375937, -0.04370089],\n",
       "        [ 0.01732371, -0.04943231,  0.02387507],\n",
       "        [ 0.03352253, -0.01579722,  0.04878741]],\n",
       "\n",
       "       [[-0.0136955 , -0.02521811, -0.04715899],\n",
       "        [ 0.04738381,  0.05001703, -0.03145186],\n",
       "        [ 0.04049386,  0.02348245,  0.01627743]],\n",
       "\n",
       "       [[ 0.02415584,  0.03840971, -0.01027263],\n",
       "        [ 0.03119494, -0.02915212, -0.03134566],\n",
       "        [ 0.02180289,  0.04078788,  0.01119361]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.232389\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 4 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 4 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 1 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:10.679472\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 2 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.287401\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 3 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.272874\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 4 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.130762\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 5 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:12.529297\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 6 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 6 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.735636\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 6 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 7 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.769781\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 8 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.149135\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "Tested mini batch 1 of 1. Tested images so far: 128\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "Tested mini batch 1 of 2. Tested images so far: 32\n",
      "Tested mini batch 2 of 2. Tested images so far: 64\n",
      "correctly classified: 5 of 50 images of dataset 'imagenette2': --> classification rate: 0.1\n",
      "Training epoch 9 finished.\n",
      "Classification rates: train=0.1, test=0.1\n",
      "Finished training batch 1 of 1. Trained images so far: 128\n",
      "Time needed for training this epoch: 0:00:11.163408\n",
      "Testing model on dataset: imagenette2\n",
      "There are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4513d8f0eee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                    stop_epochnr=100)\n\u001b[0m",
      "\u001b[0;32m/media/veracrypt1/18_src/02_courses/course_cnn/cnn_toolbox/cnn_toolbox.py\u001b[0m in \u001b[0;36mtrain_cnn_complete\u001b[0;34m(your_cnn, your_train_ds, your_test_ds, same_shuffling, stop_epochnr, stop_classification_rate_train, show_progress)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# compute classification rate on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mcl_rate_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myour_train_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0mcl_rate_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtest_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myour_test_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/veracrypt1/18_src/02_courses/course_cnn/cnn_toolbox/cnn_toolbox.py\u001b[0m in \u001b[0;36mtest_cnn\u001b[0;34m(your_cnn, your_test_ds, show_infos)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;31m# 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;31m# classify the test images now!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mneuron_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myour_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;31m# 2.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import train_cnn_complete\n",
    "\n",
    "model = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "\n",
    "train_cnn_complete(model,\n",
    "                   ds_train,\n",
    "                   ds_test,\n",
    "                   stop_epochnr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
