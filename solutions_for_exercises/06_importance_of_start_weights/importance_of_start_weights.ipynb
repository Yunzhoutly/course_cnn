{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyze how important the start weights are for a CNN.\n",
    "\n",
    "**Key question: Do the start weights have a small or large influence on the final classification performance of a CNN?**\n",
    "\n",
    "For this we conduct experiments where we start with different start weights and train a CNN till a certain classification performance is reached and then observe:\n",
    "\n",
    "- Do the training curves differ regarding their form?\n",
    "- How long does it take to reach the final classification performance threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets used for the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image datasets needed in order to conduct the experiments:\n",
    "- imagenette2: 10 very different object classes\n",
    "- imagewoof  : 10 similar object classes (10 dog breeds)\n",
    "\n",
    "Here I use the imagenette2 and imagewoof (both in the 320px versions) datasets which are available at\n",
    "\n",
    "[https://github.com/fastai/imagenette](https://github.com/fastai/imagenette)\n",
    "\n",
    "These are much smaller versions of the original imagenet dataset with only 10 object classes each.\n",
    "\n",
    "You have to download the images manually before starting the experiments!\n",
    "\n",
    "I used the 320px versions of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to image_dataset class v1.0 by Juergen Brauer\n",
      "Under root folder\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train/\n",
      "I have found the following 10 subfolders/classes:\n",
      "\n",
      "['cassette_player', 'chain_saw', 'church', 'dog_english_springer', 'fish_tench', 'french_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute']\n",
      "993 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/\n",
      "858 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//chain_saw/\n",
      "941 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//church/\n",
      "955 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//dog_english_springer/\n",
      "963 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//fish_tench/\n",
      "956 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//french_horn/\n",
      "961 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//garbage_truck/\n",
      "931 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//gas_pump/\n",
      "951 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//golf_ball/\n",
      "960 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//parachute/\n",
      "In total there are 50 images\n",
      "\n",
      "Here are the first 3 entries in the list:\n",
      "Entry #0:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/n02979186_21256.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #1:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/ILSVRC2012_val_00000557.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #2:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/train//cassette_player/ILSVRC2012_val_00002034.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Under root folder\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val/\n",
      "I have found the following 10 subfolders/classes:\n",
      "\n",
      "['cassette_player', 'chain_saw', 'church', 'dog_english_springer', 'fish_tench', 'french_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute']\n",
      "357 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/\n",
      "386 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//chain_saw/\n",
      "409 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//church/\n",
      "395 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//dog_english_springer/\n",
      "387 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//fish_tench/\n",
      "394 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//french_horn/\n",
      "389 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//garbage_truck/\n",
      "419 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//gas_pump/\n",
      "399 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//golf_ball/\n",
      "390 files in subfolder /media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//parachute/\n",
      "In total there are 50 images\n",
      "\n",
      "Here are the first 3 entries in the list:\n",
      "Entry #0:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00008651.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #1:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00020400.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Entry #2:\n",
      "\t/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/val//cassette_player/ILSVRC2012_val_00028911.JPEG\n",
      "\t0\n",
      "\tcassette_player\n",
      "\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "img_shape = (224,224,3)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../cnn_toolbox\")\n",
    "from cnn_toolbox import image_dataset\n",
    "\n",
    "root_folder = \"/media/juebrauer/Seagate Expansion Drive/datasets/01_images/18_imagenette2/320px/\"\n",
    "root_folder_train = root_folder + \"train/\"\n",
    "root_folder_test  = root_folder + \"val/\"\n",
    "\n",
    "ds_train = image_dataset(name=\"imagenette2-train\",\n",
    "                         root_folder=root_folder_train,\n",
    "                         img_size=(img_shape[0],img_shape[1]))\n",
    "\n",
    "ds_test = image_dataset(name=\"imagenette2-test\",\n",
    "                        root_folder=root_folder_test,\n",
    "                        img_size=(img_shape[0],img_shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to build CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              526336    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 3,504,394\n",
      "Trainable params: 3,504,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import create_cnn_model\n",
    "\n",
    "model1 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 8,407,882\n",
      "Trainable params: 8,407,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = create_cnn_model(model_name = \"inc_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to train a CNN for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import train_cnn_one_epoch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.set_mini_batch_size(128)\n",
    "#train_cnn_one_epoch(model1, ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test helper function to test a CNN with a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import test_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_cnn(model1, ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check availability of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following GPUs are available: []\n",
      "Nr of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import gpu_check\n",
    "gpu_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for checking on a computer with NVIDIA GPUs, whether they are used during training, enter:\n",
    "\n",
    "    watch -n1.0 nvidia-smi   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check controlability of start weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_toolbox import initialize_pseudo_random_number_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_pseudo_random_number_generators(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              526336    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 3,504,394\n",
      "Trainable params: 3,504,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import get_weights_from_conv_layer\n",
    "\n",
    "filter_weights_1, bias_weights_1 = get_weights_from_conv_layer(model1, \"conv2d\", show_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = filter_weights_1[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00225292, -0.02375937, -0.04370089],\n",
       "        [ 0.01732371, -0.04943231,  0.02387507],\n",
       "        [ 0.03352253, -0.01579722,  0.04878741]],\n",
       "\n",
       "       [[-0.0136955 , -0.02521811, -0.04715899],\n",
       "        [ 0.04738381,  0.05001703, -0.03145186],\n",
       "        [ 0.04049386,  0.02348245,  0.01627743]],\n",
       "\n",
       "       [[ 0.02415584,  0.03840971, -0.01027263],\n",
       "        [ 0.03119494, -0.02915212, -0.03134566],\n",
       "        [ 0.02180289,  0.04078788,  0.01119361]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_weights_2, bias_weights_2 = get_weights_from_conv_layer(model2, \"conv2d\", show_info=True)\n",
    "f2 = filter_weights_2[:,:,:,0]\n",
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the random number generators\n",
    "# with the same random seed that we used when\n",
    "# we generated model1a\n",
    "initialize_pseudo_random_number_generators(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_weights has shape: (3, 3, 3, 256)\n",
      "bias_weights has shape: (256,)\n",
      "filter_weights has type: <class 'numpy.ndarray'>\n",
      "bias_weights has type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "model3 = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                          input_shape = img_shape,\n",
    "                          nr_outputs = ds_train.nr_classes)\n",
    "filter_weights_3, bias_weights_3 = get_weights_from_conv_layer(model3, \"conv2d\", show_info=True)\n",
    "f3 = filter_weights_3[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03397892, -0.02063269, -0.03835453],\n",
       "        [ 0.02216351, -0.01557614, -0.04525996],\n",
       "        [ 0.02965986,  0.04531969,  0.03822213]],\n",
       "\n",
       "       [[ 0.01318451,  0.00451758, -0.02655915],\n",
       "        [ 0.04403731,  0.00551137,  0.03676816],\n",
       "        [ 0.00215926, -0.02074016,  0.00352234]],\n",
       "\n",
       "       [[ 0.02060153, -0.01723271, -0.01694306],\n",
       "        [ 0.02090051, -0.02011791,  0.02081885],\n",
       "        [-0.01326452, -0.04043265,  0.04245097]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00225292, -0.02375937, -0.04370089],\n",
       "        [ 0.01732371, -0.04943231,  0.02387507],\n",
       "        [ 0.03352253, -0.01579722,  0.04878741]],\n",
       "\n",
       "       [[-0.0136955 , -0.02521811, -0.04715899],\n",
       "        [ 0.04738381,  0.05001703, -0.03145186],\n",
       "        [ 0.04049386,  0.02348245,  0.01627743]],\n",
       "\n",
       "       [[ 0.02415584,  0.03840971, -0.01027263],\n",
       "        [ 0.03119494, -0.02915212, -0.03134566],\n",
       "        [ 0.02180289,  0.04078788,  0.01119361]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "train_cnn_complete: starting to train the model\n",
      "-----------------------------------------------\n",
      "test_cnn: there are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "test_cnn: tested mini batch 1 of 1. Tested images so far: 50\n",
      "test_cnn: correctly classified: 5 of 50 images of dataset 'imagenette2-train': --> classification rate: 0.10\n",
      "test_cnn: there are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "test_cnn: tested mini batch 1 of 2. Tested images so far: 32\n",
      "test_cnn: tested mini batch 2 of 2. Tested images so far: 50\n",
      "test_cnn: correctly classified: 5 of 50 images of dataset 'imagenette2-test': --> classification rate: 0.10\n",
      "\n",
      "\n",
      "********************************************************\n",
      "train_cnn_complete: starting training epoch 1\n",
      "train_cnn_one_epoch: finished training batch 1 of 1. Trained images so far: 50\n",
      "train_cnn_one_epoch: time needed for training this epoch: 0:00:11.595730\n",
      "********************************************************\n",
      "\n",
      "\n",
      "test_cnn: there are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "test_cnn: tested mini batch 1 of 1. Tested images so far: 50\n",
      "test_cnn: correctly classified: 5 of 50 images of dataset 'imagenette2-train': --> classification rate: 0.10\n",
      "test_cnn: there are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "test_cnn: tested mini batch 1 of 2. Tested images so far: 32\n",
      "test_cnn: tested mini batch 2 of 2. Tested images so far: 50\n",
      "test_cnn: correctly classified: 5 of 50 images of dataset 'imagenette2-test': --> classification rate: 0.10\n",
      "train_cnn_complete: training epoch 1 finished.\n",
      "train_cnn_complete: classification rates: train=0.10, test=0.10\n",
      "\n",
      "\n",
      "********************************************************\n",
      "train_cnn_complete: starting training epoch 2\n",
      "train_cnn_one_epoch: finished training batch 1 of 1. Trained images so far: 50\n",
      "train_cnn_one_epoch: time needed for training this epoch: 0:00:11.126378\n",
      "********************************************************\n",
      "\n",
      "\n",
      "test_cnn: there are 50 testing images. So for a batch size of 128 we have to test 1 batches.\n",
      "test_cnn: tested mini batch 1 of 1. Tested images so far: 50\n",
      "test_cnn: correctly classified: 6 of 50 images of dataset 'imagenette2-train': --> classification rate: 0.12\n",
      "test_cnn: there are 50 testing images. So for a batch size of 32 we have to test 2 batches.\n",
      "test_cnn: tested mini batch 1 of 2. Tested images so far: 32\n",
      "test_cnn: tested mini batch 2 of 2. Tested images so far: 50\n",
      "test_cnn: correctly classified: 6 of 50 images of dataset 'imagenette2-test': --> classification rate: 0.12\n",
      "train_cnn_complete: training epoch 2 finished.\n",
      "train_cnn_complete: classification rates: train=0.12, test=0.12\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "train_cnn_complete: time needed for training the complete model: 0:00:42.883844\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from cnn_toolbox import train_cnn_complete\n",
    "from cnn_toolbox import save_history\n",
    "\n",
    "model = create_cnn_model(model_name = \"same_nr_filters\",\n",
    "                         input_shape = img_shape,\n",
    "                         nr_outputs = ds_train.nr_classes)\n",
    "\n",
    "history = train_cnn_complete(model,\n",
    "                             ds_train,\n",
    "                             ds_test,\n",
    "                             stop_epochnr=2)\n",
    "\n",
    "fname = \"model01.history\"\n",
    "save_history(history, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cl_rate_train': [0.1, 0.1, 0.12], 'cl_rate_test': [0.1, 0.1, 0.12]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
